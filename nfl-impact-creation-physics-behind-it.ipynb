{"cells":[{"metadata":{},"cell_type":"markdown","source":"Updated in v4:\n\n1. I also added animations with impact events markers.\n\nUpdated in v3:\n\n1. I just found this [message from the host](https://www.kaggle.com/c/nfl-impact-detection/discussion/198728#1087657) and to meet this, I need to shift 0.1 from the 'ball_snap'.\n\n> The videos begin 10 frames before the snap. The tracking data contains an \"event\" column in which the \"ball_snap\" is recorded. The Sideline and Endzone views have been time-synced such that the snap occurs 10 frames into the video. This time alignment should be considered to be accurate to within +/- 3 frames or 0.05 seconds (video data is recorded at approximately 59.94 frames per second). If you do some math with frame rate etc., you can align the tracking data with the video data. It will be close, but not exact because the video data is recorded at 60 HZ and the NGS data at 10 HZ.\n\n2. `make_alignment` function had a bug. Fixed.\n\n\nUpdated in v2:\n\n1. Make the animation larger so that you can see the player better.\n2. Annotate `train_player_tracking.csv` with impact event."},{"metadata":{},"cell_type":"markdown","source":"## About \n\nIn this notebook, I create animated datasets of `train_player_tracking.csv` and `test_player_tracking.csv` using `matplotlib`.\nI try to make it aligned with video files, so it could be used to help find the impact frame or maybe you can further use that to find where the impact occured."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import datetime as dt\nimport warnings\n\nimport cv2\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\nfrom IPython.display import Video\nfrom pathlib import Path\n\nfrom matplotlib import animation\nfrom matplotlib import patches\nfrom tqdm.notebook import tqdm\n\nwarnings.simplefilter(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"## Utilities\n\nCopied from https://www.kaggle.com/samhuddleston/nfl-1st-and-future-getting-started , but originally used in https://www.kaggle.com/robikscube/nfl-big-data-bowl-plotting-player-position/notebook."},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_football_field(linenumbers=True,\n                          endzones=True,\n                          highlight_line=False,\n                          highlight_line_number=50,\n                          highlighted_name='Line of Scrimmage',\n                          fifty_is_los=False,\n                          figsize=(12, 6.33)):\n    \"\"\"\n    Function that plots the football field for viewing plays.\n    Allows for showing or hiding endzones.\n    \"\"\"\n    rect = patches.Rectangle((0, 0), 120, 53.3, linewidth=0.1,\n                             edgecolor='r', facecolor='forestgreen', zorder=0)  # changed the field color to forestgreen\n\n    fig, ax = plt.subplots(1, figsize=figsize)\n    ax.add_patch(rect)\n\n    plt.plot([10, 10, 10, 20, 20, 30, 30, 40, 40, 50, 50, 60, 60, 70, 70, 80,\n              80, 90, 90, 100, 100, 110, 110, 120, 0, 0, 120, 120],\n             [0, 0, 53.3, 53.3, 0, 0, 53.3, 53.3, 0, 0, 53.3, 53.3, 0, 0, 53.3,\n              53.3, 0, 0, 53.3, 53.3, 0, 0, 53.3, 53.3, 53.3, 0, 0, 53.3],\n             color='white')\n    if fifty_is_los:\n        plt.plot([60, 60], [0, 53.3], color='gold')\n        plt.text(62, 50, '<- Player Yardline at Snap', color='gold')\n    # Endzones\n    if endzones:\n        ez1 = patches.Rectangle((0, 0), 10, 53.3,\n                                linewidth=0.1,\n                                edgecolor='r',\n                                facecolor='blue',\n                                alpha=0.2,\n                                zorder=0)\n        ez2 = patches.Rectangle((110, 0), 120, 53.3,\n                                linewidth=0.1,\n                                edgecolor='r',\n                                facecolor='blue',\n                                alpha=0.2,\n                                zorder=0)\n        ax.add_patch(ez1)\n        ax.add_patch(ez2)\n    plt.xlim(0, 120)\n    plt.ylim(-5, 58.3)\n    plt.axis('off')\n    if linenumbers:\n        for x in range(20, 110, 10):\n            numb = x\n            if x > 50:\n                numb = 120 - x\n            plt.text(x, 5, str(numb - 10),\n                     horizontalalignment='center',\n                     fontsize=20,  # fontname='Arial',\n                     color='white')\n            plt.text(x - 0.95, 53.3 - 5, str(numb - 10),\n                     horizontalalignment='center',\n                     fontsize=20,  # fontname='Arial',\n                     color='white', rotation=180)\n    if endzones:\n        hash_range = range(11, 110)\n    else:\n        hash_range = range(1, 120)\n\n    for x in hash_range:\n        ax.plot([x, x], [0.4, 0.7], color='white')\n        ax.plot([x, x], [53.0, 52.5], color='white')\n        ax.plot([x, x], [22.91, 23.57], color='white')\n        ax.plot([x, x], [29.73, 30.39], color='white')\n\n    if highlight_line:\n        hl = highlight_line_number + 10\n        plt.plot([hl, hl], [0, 53.3], color='yellow')\n        plt.text(hl + 2, 50, '<- {}'.format(highlighted_name),\n                 color='yellow')\n    return fig, ax","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Load Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"track_data = pd.read_csv(\"../input/nfl-impact-detection/train_player_tracking.csv\")\ntrack_data[\"time\"] = pd.to_datetime(track_data[\"time\"])\ntrack_data[\"color\"] = track_data[\"player\"].map(lambda x: \"black\" if \"H\" in x else \"white\")\ntrack_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_labels = pd.read_csv(\"../input/nfl-impact-detection/train_labels.csv\")\ntrain_labels.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Create train_player_tracking.csv with impact annotation\n\nI modify `train_player_tracking.csv` to only include tracking data that is in the video and annotate the tracking data point where impacts occured.\nTo do this I first make alignment between tracking data and frames, and determine the time where impact occured by picking the closest time to the imact frame."},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_alignment(train_track: pd.DataFrame, train_label: pd.DataFrame, video_dir: Path, game_key: int, play_id: int):\n    play_track = train_track.query(f\"gameKey == {game_key} & playID == {play_id}\")\n    play_label = train_label.query(f\"gameKey == {game_key} & playID == {play_id}\")\n    \n    play_track[\"impact\"] = 0\n    \n    snap_frame = play_track.query(\"event == 'ball_snap'\")\n    snap_time = snap_frame[\"time\"].iloc[0]\n    snap_time -= dt.timedelta(seconds=0.1)\n    \n    video_name = f\"{game_key}_{str(play_id).rjust(6, '0')}_Endzone.mp4\"\n    video = cv2.VideoCapture(str(video_dir / video_name))\n    \n    fps = video.get(cv2.CAP_PROP_FPS)\n    nframes = play_label.frame.nunique()\n    \n    duration = nframes / fps\n    end_time = snap_time + dt.timedelta(seconds=duration)\n    \n    play = play_track.loc[(play_track[\"time\"] >= snap_time) & (play_track[\"time\"] < end_time)].copy()\n    \n    impact_frames = play_label.query(\"impact == 1 & view == 'Endzone'\")\n    for _, row in impact_frames.iterrows():\n        frame = row.frame\n        label = row.label\n        time_from_start = frame / fps\n        time = snap_time + dt.timedelta(seconds=time_from_start)\n        \n        abs_timedelta = abs(play[\"time\"] - time).dt.total_seconds()\n        min_abs_timedelta = abs_timedelta.min()\n        impact_point_index = play[abs_timedelta == min_abs_timedelta].query(\n            f\"player == '{label}'\").index[0]\n        play.loc[impact_point_index, \"impact\"] = 1\n    play = play.reset_index(drop=False)\n    return play","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pairs = track_data.groupby([\"gameKey\", \"playID\"]).count().index.tolist()\nvideo_dir = Path(\"../input/nfl-impact-detection/train/\")\n\nplay_trackings = []\nfor game_key, play_id in pairs:\n    play_trackings.append(make_alignment(track_data, train_labels, video_dir, game_key, play_id))\n    \nannotated_trackings = pd.concat(play_trackings, axis=0).reset_index(drop=True)\nannotated_trackings.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"annotated_trackings.query(\"impact == 1 & gameKey == 57583 & playID == 82\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_labels.query(\"impact == 1 & gameKey == 57583 & playID == 82 & view == 'Endzone'\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(annotated_trackings.query(\n    \"impact == 1 & gameKey == 57583 & playID == 82\")), len(train_labels.query(\n    \"impact == 1 & gameKey == 57583 & playID == 82 & view == 'Endzone'\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"annotated_trackings.to_csv(\"train_player_tracking_annotated.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Animation"},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_animation(play_track: pd.DataFrame, video_dir: Path, save_dir: Path):\n    fig, ax = create_football_field(figsize=(24, 12.66))\n\n    snap_frame = play_track.query(\"event == 'ball_snap'\")\n    snap_time = snap_frame[\"time\"].iloc[0]\n    snap_time -= dt.timedelta(seconds=0.1)\n    \n    game_key = play_track[\"gameKey\"].iloc[0]\n    play_id = play_track[\"playID\"].iloc[0]\n    \n    video_name = f\"{game_key}_{str(play_id).rjust(6, '0')}_Endzone.mp4\"\n    video = cv2.VideoCapture(str(video_dir / video_name))\n    \n    fps = video.get(cv2.CAP_PROP_FPS)\n    nframes = 0\n    while True:\n        worked, _ = video.read()\n        if not worked:\n            break\n        nframes += 1\n    \n    duration = nframes / fps\n    end_time = snap_time + dt.timedelta(seconds=duration)\n    \n    play = play_track.loc[(play_track[\"time\"] >= snap_time) & (play_track[\"time\"] < end_time)]\n\n    unique_times = play.time.unique()\n    \n    show_impact_marker = \"impact\" in play_track.columns\n    \n    # initialize the plot\n    points = {}\n    annotations = {}\n    obj_list = []\n    start_time = unique_times[0]\n    tracking_at_that_moment = play[play[\"time\"] == start_time]\n    for _, row in tracking_at_that_moment.iterrows():\n        player_id = row.player\n        x, y = row.x, row.y\n        if show_impact_marker:\n            impact = row.impact\n            color = row.color if impact == 0 else \"red\"\n        else:\n            color = row.color\n        plot_obj = ax.scatter(x, y, color=color, s=70)\n        anno_obj = ax.annotate(player_id,\n                               (x, y),\n                               verticalalignment=\"center\",\n                               horizontalalignment=\"center\",\n                               color=\"white\" if color == \"black\" else \"black\",\n                               fontsize=10)\n        points[player_id] = plot_obj\n        annotations[player_id] = anno_obj\n        obj_list.append(plot_obj)\n        obj_list.append(anno_obj)\n        \n    def init():\n        return obj_list\n        \n    def update(step: int):\n        time = unique_times[step]\n        tracking_at_that_moment = play[play[\"time\"] == time]\n        for _, row in tracking_at_that_moment.iterrows():\n            player_id = row.player\n            x, y = row.x, row.y\n            points[player_id].set_offsets(np.array([x, y]))\n            if show_impact_marker:\n                impact = row.impact\n                color = row.color if impact == 0 else \"red\"\n                points[player_id].set_color(color)\n            annotations[player_id].set_x(x)\n            annotations[player_id].set_y(y)\n        return obj_list\n    \n    ani = animation.FuncAnimation(\n        fig, update, frames=len(unique_times), interval=100, init_func=init)\n    ani.save(save_dir / f\"{game_key}_{str(play_id).rjust(6, '0')}_Tracking.mp4\")\n    plt.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"game_key = track_data.loc[0, \"gameKey\"]\nplay_id = track_data.loc[0, \"playID\"]\nplay_track = track_data.query(f\"gameKey == {game_key} & playID == {play_id}\")\n\nvideo_dir = Path(\"../input/nfl-impact-detection/train/\")\nsave_dir = Path(\"./\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"create_animation(play_track, video_dir, save_dir)\n!ls","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Video(data=\"./57583_000082_Tracking.mp4\", embed=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In version 4, I also created anomations with impact marker."},{"metadata":{"trusted":true},"cell_type":"code","source":"play_track = annotated_trackings.query(f\"gameKey == {game_key} & playID == {play_id}\")\ncreate_animation(play_track, video_dir, save_dir)\nVideo(data=\"./57583_000082_Tracking.mp4\", embed=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Red markers correspond to impact events.\n\nThis animation corresponds to the play of `57583_000082_Endzone.mp4` and `57583_000082_Sideline.mp4`. Let's check it out."},{"metadata":{"trusted":true},"cell_type":"code","source":"Video(data=\"../input/nfl-impact-detection/train/57583_000082_Endzone.mp4\", embed=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Video(data=\"../input/nfl-impact-detection/train/57583_000082_Sideline.mp4\", embed=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Create this animation for all the train set"},{"metadata":{"trusted":true},"cell_type":"code","source":"save_dir = Path(\"./train_tracking\")\nsave_dir.mkdir(exist_ok=True, parents=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pairs = track_data.groupby([\"gameKey\", \"playID\"]).count().index.tolist()\npairs[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for game_key, play_id in tqdm(pairs):\n    play_track = track_data.query(f\"gameKey == {game_key} & playID == {play_id}\")\n    create_animation(play_track, video_dir, save_dir)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"save_dir = Path(\"./train_tracking_with_impact_marker\")\nsave_dir.mkdir(exist_ok=True, parents=True)\nfor game_key, play_id in tqdm(pairs):\n    play_track = annotated_trackings.query(f\"gameKey == {game_key} & playID == {play_id}\")\n    create_animation(play_track, video_dir, save_dir)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Create this animation for all the test set"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_track_data = pd.read_csv(\"../input/nfl-impact-detection/test_player_tracking.csv\")\ntest_track_data[\"time\"] = pd.to_datetime(test_track_data[\"time\"])\ntest_track_data[\"color\"] = test_track_data[\"player\"].map(lambda x: \"black\" if \"H\" in x else \"white\")\nsave_dir = Path(\"./test_tracking\")\nsave_dir.mkdir(exist_ok=True, parents=True)\n\npairs = test_track_data.groupby([\"gameKey\", \"playID\"]).count().index.tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"video_dir = Path(\"../input/nfl-impact-detection/test\")\nfor game_key, play_id in tqdm(pairs):\n    play_track = test_track_data.query(f\"gameKey == {game_key} & playID == {play_id}\")\n    create_animation(play_track, video_dir, save_dir)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## EOF"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}